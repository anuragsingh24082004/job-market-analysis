# -*- coding: utf-8 -*-
"""nlp_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Uza7Alng9KUWZkJggGc819jXl1JP-ex
"""

import pandas as pd
import nltk
from sklearn.feature_extraction.text import CountVectorizer
import matplotlib.pyplot as plt
from wordcloud import WordCloud

nltk.download('stopwords')
from nltk.corpus import stopwords

def clean_and_extract_keywords(csv_path="data/jobs.csv"):
    df = pd.read_csv(csv_path)
    summaries = df['summary'].fillna('').tolist()
    stop_words = stopwords.words('english')

    vectorizer = CountVectorizer(stop_words=stop_words, max_features=50)
    X = vectorizer.fit_transform(summaries)

    words = vectorizer.get_feature_names_out()
    freqs = X.toarray().sum(axis=0)

    word_freq = pd.DataFrame({'word': words, 'frequency': freqs}).sort_values(by='frequency', ascending=False)

    # WordCloud
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(summaries))
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title("TOP KEYWORDS IN JOB DESCRIPTIONS")
    plt.show()

    return word_freq

if __name__ == "__main__":
    print(clean_and_extract_keywords())